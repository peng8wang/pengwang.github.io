<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="lai.css" type="text/css" />
<title>Peng Wang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Peng Wang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="experience.html">Experience</a></div>
<div class="menu-item"><a href="activity.html">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Peng Wang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="tianlai.jpg" alt="Peng Wang Photo" width="150px" />&nbsp;</td>
<td align="left"><p><b>Peng Wang</b> <br />
Postdoc Research Fellow <br />
</p>
<p><a href="https://eecs.engin.umich.edu/" target=&ldquo;blank&rdquo;>Department of Electrical Engineering and Computer Science</a> <br /> 
<a href="https://umich.edu/" target=&ldquo;blank&rdquo;>University of Michigan, Ann Arbor</a> <br />
<br />
<b>Office</b>: Room 3218, EECS Building, 1301 Beal Avenue, Ann Arbor, MI 48109-2122 <br />
<b>Email</b>: pengwa@umich.edu <br />
<a href="https://scholar.google.com/citations?user=baF3HKUAAAAJ&amp;hl=zh-TW" target=&ldquo;blank&rdquo;>Google Scholar</a>
</p>
</td></tr></table>
<h2>About Me</h2>
<p>I am currently a postdoc research fellow advised by Professors <a href="https://web.eecs.umich.edu/~girasole/" target=&ldquo;blank&rdquo;>Laura Balzano</a> and <a href="https://qingqu.engin.umich.edu/" target=&ldquo;blank&rdquo;>Qing Qu</a> at <a href="https://umich.edu/" target=&ldquo;blank&rdquo;>University of Michigan</a>. Before that, I got my Ph.D. degree in Systems Engineering and Engineering Management advised by Professor <a href="https://www1.se.cuhk.edu.hk/~manchoso/" target=&ldquo;blank&rdquo;>Anthony Man-Cho So</a> at <a href="https://www.cuhk.edu.hk/" target=&ldquo;blank&rdquo;>The Chinese University of Hong Kong</a>.
</p>
<h2>Research Interests </h2>
<p>Broadly speaking, my research interest lies in the intersects of optimization, machine learning, and data science. Specifically, I am interested in exploring the low-complexity models of learning problems in applications and developing advanced theory and efficient algorithms to understand and solve these problems. I aim to not only enhance our understanding of data-driven processes but also enable us to make informed decisions, optimize the workflows, and develop more effective and efficient solutions.
</p>
<p><b> Feel free to email me if you are interested in my research. Remote collaboration is also welcome!</b> 
</p>
<h2>What's New</h2>
<ul>
<li><p>[November, 2023] <a href="https://arxiv.org/pdf/2311.02960.pdf" target=&ldquo;blank&rdquo;>One paper</a> on understanding <b>hierarchical representation learning</b> via low-dimensinoal modeling is posted!  
</p>
</li>
<li><p>[October, 2023] I was selected to receive the <a href="https://cpal.cc/rising_stars" target=&ldquo;blank&rdquo;><b>Rising Star Award</b></a> at <a href="https://cpal.cc/" target=&ldquo;blank&rdquo;><b>CPAL 2024</b></a>! 
</p>
</li>
<li><p>[October, 2023] <a href="https://arxiv.org/pdf/2310.05351.pdf" target=&ldquo;blank&rdquo;>One paper</a> on the <b>generalized neural collapse</b> is posted! 
</p>
</li>
<li><p>[June, 2023] <a href="https://arxiv.org/pdf/2306.01154.pdf" target=&ldquo;blank&rdquo;>One paper</a> on the <b>low-dimensional updates</b> of gradient descent for deep networks is posted!
</p>
</li>
<li><p>[April, 2023] <a href="https://arxiv.org/pdf/2301.00423.pdf" target=&ldquo;blank&rdquo;>One paper</a> on <b>chance constrained programming</b> is posted!  
</p>
</li>
<li><p>[November, 2022] <a href="https://arxiv.org/pdf/2107.07107.pdf" target=&ldquo;blank&rdquo;>One paper</a> on L1-PCA has been accepted by SIOPT!
</p>
</li>
<li><p>[Septembe, 2022] <a href="https://arxiv.org/pdf/2209.09211.pdf" target=&ldquo;blank&rdquo;>One paper</a> on neural collapse has been accepted by NeurIPS 2022!


</p>
</li>
</ul>
<h2>Preprint Papers</h2>
<ul>
<li><p><b>Peng Wang</b>*, Xiao Li*, Can Yaras, Wei Hu, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu. Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination, 2023. Submitted to <b><i>Journal of Machine Learning Research</i></b>, 2024. [<a href="https://arxiv.org/pdf/2311.02960.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p>Can Yaras*, <b>Peng Wang</b>*, Wei Hu, Zhihui Zhu, Laura Balzano, Qing Qu. The Law of Parsimony in Gradient Descent for Learning Deep Linear Networks, 2023. In submission. [<a href="https://arxiv.org/pdf/2306.01154.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>, Rujun Jiang, Qingyuan Kong, Laura Balzano. Proximal DC Algorithm for Sample Average Approximation of Chance Constrained Programming: Convergence and Numerical Results. Submitted to <b><i>SIAM Journal on Optimization</i></b>, 2023. [<a href="https://arxiv.org/pdf/2301.00423.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p>Jiachen Jiang, Jinxin Zhou, <b>Peng Wang</b>, Qing Qu, Dustin Mixon, Chong You, Zhihui Zhu. Generalized Neural Collapse for a Large Number of Classes, 2023. [<a href="https://arxiv.org/pdf/2310.05351.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p>Taoli Zheng, <b>Peng Wang</b>, Anthony Man-Cho So. A Linearly Convergent Algorithm for Rotationally Invariant L1-Norm Principal Component Analysis, 2022. [<a href="https://arxiv.org/pdf/2210.05066.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
</ul>
<h2>Journal Papers</h2>
<ul>
<li><p><b>Peng Wang</b>, Huikang Liu, Anthony Man-Cho So. Linear Convergence of Proximal Alternating Minimization Method with Extrapolation for L1-Norm Principal Component Analysis. <b><i>SIAM Journal on Optimization</i></b> (2023) 33(2):684-712. [<a href="https://arxiv.org/pdf/2107.07107.pdf" target=&ldquo;blank&rdquo;>paper</a>] 
</p>
</li>
<li><p><b>Peng Wang</b>, Zirui Zhou, Anthony Man-Cho So. Non-Convex Exact Community Recovery in Stochastic Block Model. <b><i>Mathematical Programming, Series A</i></b> (2022) 195(1-2):793-829. [<a href="https://arxiv.org/pdf/2006.15843v4.pdf" target=&ldquo;blank&rdquo;>paper</a>] 
</p>
</li>
</ul>
<h2>Conference Papers (&lsquo;&lsquo;*&rsquo;&rsquo; denotes equal contribution.)</h2>
<ul>
<li><p>Can Yaras*, <b>Peng Wang</b>*, Wei Hu, Zhihui Zhu, Laura Balzano, Qing Qu. Invariant Low-Dimensional Subspaces in Gradient Descent for Learning Deep Matrix Factorizations. To appear in <b><i>NeurIPS M3L 2023</i></b>.
</p>
</li>
<li><p>Jinxin Wang, Yuen-Man Pun, Xiaolu Wang, <b>Peng Wang</b>, Anthony Man-Cho So. Projected Tensor Power Method for Hypergraph Community Recovery. <b><i>ICML 2023</i></b>.  [<a href="https://openreview.net/pdf?id=CcDKqUR546" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>*, Huikang Liu*, Can Yaras*, Laura Balzano, Qing Qu. Linear Convergence Analysis of Neural Collapse with Unconstrained Features. NeurIPS Workshop on Optimization for Machine Learning, <b><i>NeurIPS OPT 2022</i></b>. [<a href="https://openreview.net/pdf?id=WC9im-M_y5" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p>Can Yaras*, <b>Peng Wang</b>*, Zhihui Zhu, Laura Balzano, Qing Qu. Neural Collapse with Normalized Features: A Geometric Analysis over the Riemannian Manifold. <b><i>NeurIPS 2022</i></b>. [<a href="https://arxiv.org/pdf/2209.09211.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>, Huikang Liu, Anthony Man-Cho So, Laura Balzano. Convergence and Recovery Guarantees of the K-Subspaces Method for Subspace Clustering. <b><i>ICML 2022</i></b>. [<a href="https://arxiv.org/pdf/2206.05553.pdf" target=&ldquo;blank&rdquo;>paper</a>] 
</p>
</li>
<li><p>Xiaolu Wang, <b>Peng Wang</b>, Anthony Man-Cho So. Exact Community Recovery over Signed Graphs. <b><i>AISTATS 2022</i></b>. [<a href="https://arxiv.org/pdf/2202.12255.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>, Huikang Liu, Zirui Zhou, Anthony Man-Cho So. Optimal Non-Convex Exact Recovery in Stochastic Block Model via Projected Power Method. <b><i>ICML 2021</i></b>. [<a href="https://arxiv.org/pdf/2106.05644.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>*, Zirui Zhou*, Anthony Man-Cho So. A Nearly-Linear Time Algorithm for Exact Community Recovery in Stochastic Block Model. <b><i>ICML 2020</i></b>. [<a href="http://proceedings.mlr.press/v119/wang20ac/wang20ac.pdf" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p><b>Peng Wang</b>, Huikang Liu, Anthony Man-Cho So. Globally Convergent Accelerated Proximal Alternating Maximization Method for L1-Principal Component Analysis. <b><i>ICASSP 2019</i></b> (IEEE SPS Student Travel Award). [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8682499" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
<li><p>Huikang Liu, <b>Peng Wang</b>, Anthony Man-Cho So. Fast First-Order Methods for the Massive Robust Multicast Beamforming Problem with Interference Temperature Constraints. <b><i>ICASSP 2019</i></b>. [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683524" target=&ldquo;blank&rdquo;>paper</a>]
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-01-19 00:13:51 China Standard Time, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
